const path = require('path');
const fs = require('fs');

// åŠ è½½æ‰€æœ‰mapperæ–‡ä»¶
function loadMappers() {
  const mappers = {};
  const mappersPath = path.join(__dirname, '../mapper');
  
  // æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
  if (fs.existsSync(mappersPath)) {
    const files = fs.readdirSync(mappersPath);
    
    for (const file of files) {
      if (file.endsWith('.js')) {
        const name = path.basename(file, '.js');
        mappers[name] = require(path.join(mappersPath, file));
      }
    }
  }
  
  return mappers;
}

module.exports = {
  // åº”ç”¨å¯åŠ¨æ—¶åŠ è½½æ‰€æœ‰SQL mapper
  get mapper() {
    if (!this._mapper) {
      this._mapper = loadMappers();
    }
    return this._mapper;
  },

  /**
   * åº”ç”¨å¯åŠ¨å®Œæˆåçš„åˆå§‹åŒ–
   */
  async didReady() {
    // å¯åŠ¨çˆ¬è™«æœåŠ¡
    try {
      this.logger.info('ğŸš€ Application ready, starting crawler...');

      // å»¶è¿Ÿ5ç§’å¯åŠ¨çˆ¬è™«ï¼Œç¡®ä¿æ‰€æœ‰æœåŠ¡éƒ½å·²åˆå§‹åŒ–
      setTimeout(async () => {
        try {
          const ctx = this.createAnonymousContext();
          await ctx.service.crawler.startCrawler();
        } catch (error) {
          this.logger.error('Failed to start crawler:', error);
        }
      }, 5000);

    } catch (error) {
      this.logger.error('Failed to initialize crawler:', error);
    }
  },

  /**
   * è·å–çˆ¬è™«ç»Ÿè®¡ä¿¡æ¯
   */
  getCrawlerStats() {
    const ctx = this.createAnonymousContext();
    return ctx.service.crawler.getCrawlStats();
  },

  /**
   * æ‰‹åŠ¨è§¦å‘çˆ¬å–
   */
  async triggerCrawl(period = 'daily', language = null, limit = 50) {
    const ctx = this.createAnonymousContext();
    return await ctx.service.crawler.manualCrawl(period, language, limit);
  }
};